## Tidy

Once the data was imported, my next goal was to bring it into a tidy format where each variable had its own column, each observation represented a single stroke, and each cell contained only one value. The ShuttleSet dataset already came in a partially tidy structure, but because it was stored hierarchically—one folder per match, with separate CSV files for each set—it required significant consolidation and standardization before analysis could begin. I started by loading the `match.csv` file, which contains metadata for every match in the dataset, including tournament details, round, year, duration, winner, and loser. From here, I filtered down to only the matches where Chou Tien-Chen was either the winner or the loser, as he was the focus of my study. To make the subsequent joins more reliable, I assigned each match a unique `match_id`, since relying on names or string fields alone can easily cause merge errors.

For each match in this filtered metadata table, I iterated through its associated folder and read in the set-level CSV files. Each set file already contained stroke-by-stroke data in a long format, but I appended identifying columns for `match_id` and `set_id` so that all strokes could be combined into one unified `rally_data` table. At this stage, I also noticed that shot types were stored in Chinese. To make them easier to interpret and model, I created a translation table mapping each Chinese term to an English equivalent (for example, `"殺球"` became `"smash"`, `"放小球"` became `"net shot"`). I replaced the original column with the translated values so that downstream plots, tables, and models would be immediately interpretable without additional lookups.

Next, I joined the stroke-level data with the match metadata, adding tournament context and identifying the player who executed each shot. The original files used “A” and “B” to label players, so I mapped these to the actual player names based on whether they were the winner or loser of the match. I also determined the winner of each rally using the `getpoint_player` field. Some variables, like `backhand`, had missing values—these appeared to mean “false” rather than “unknown”—so I replaced `NA` values with zeros to make them explicit.

One of the biggest challenges came from the `homography.csv` file, which is necessary to convert pixel coordinates from video frames into real court coordinates. This file was not tidy: the homography matrix for each match was stored as a single string rather than as a usable matrix. I wrote a parser to extract the numbers, reshape them into a \(3\times3\) matrix, and store them in a list column so they could be applied to each stroke’s positional data. Using this transformation, I converted shuttle landing positions, as well as player and opponent positions, into a standardised court coordinate system. Because the player hitting the shot changes from stroke to stroke, I created new columns so that `chou_x` and `chou_y` always referred to Chou Tien-Chen’s position, and `opp_x` and `opp_y` always referred to his opponent’s position, regardless of who played the stroke. This consistent reference frame made it possible to compare positions across rallies and matches without worrying about player-side swaps.

Before moving forward, I wanted to verify that my coordinate system aligned correctly with the actual court. From the homography data, I transformed the pixel coordinates for the four corners of the court and saved them as `court_coordinates`. These became important later for both plotting and validating that all shuttle and player positions fell within reasonable bounds.

With positions transformed and roles standardised, I dropped the original pixel coordinates and other intermediate variables, renaming columns like `ball_round` to `stroke` and `type` to `shot_type` to better reflect their meaning. I then tackled data quality issues. Some rallies contained unknown shot types, missing coordinates, or mismatched shot counts compared to the actual rally—likely due to errors in the computer vision tracking. Rather than attempting to impute positions, which could bias spatial patterns in such a small dataset, I chose to remove these problematic rallies entirely. This conservative approach ensured that the dataset feeding into my model was as accurate and internally consistent as possible, even if it meant reducing the number of observations.

Finally, I added some lightweight feature engineering. Within each set, rallies were divided into “early,” “mid,” and “late” phases based on their sequence order, allowing for potential analysis of how tactics or shot effectiveness change over time. Tournament names were also cleaned by removing trailing year values to prevent the same tournament from appearing as multiple factor levels. As a final check, I created a set-level summary table (`set_data`) by taking the last stroke of each set to record the set winner and final scores for both Chou and his opponent.

The cleaning process produced four tidy outputs: `matches_metadata.csv` with the filtered matches and stable IDs, `court_coordinates.csv` with the transformed court corners, `rally_data.csv` with the fully cleaned and transformed stroke-level data, and `set_data.csv` with final set outcomes. Together, these form a consistent, analysis-ready foundation for modeling rally outcomes and building the interactive Shiny app.

